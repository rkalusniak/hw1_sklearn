{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd62841c-1c3f-418e-9e09-78fb0a8c6090",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Problem\n",
    "Our overall goal is to build classifier models to predict price_gt_1M using the the other variables. You must use sklearn Pipelines that contain your preprocessing steps and your model estimation step. We did this in the class notes.\n",
    "\n",
    "You should do your work in a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e5f4626-9da7-452f-9155-a786bbaf1101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76a6c077-e458-4bea-84a3-e54725e332b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "import sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d95ade14-5125-4b9b-ba82-91fc340c3e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d990da1f-dbec-49cf-bb1a-48aa4affdd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eabe03-881c-4d63-a5df-830821baa315",
   "metadata": {},
   "source": [
    "## Task 3 - EDA\n",
    "\n",
    "I suggest you start by reading the csv file into a pandas dataframe. I called my dataframe, `housing_df`.\n",
    "Then start with some basic EDA. You can certainly use automated tools such as pandas-profiling, skimpy or SweetViz as I showed in the class notes. Remember, when you run some of those tools, you **must** have your notebook open in the classic Jupyter Notebook interface (and **NOT** in Jupyter Lab) Check their docs to see if Jupyter Lab is supported yet. I pip installed SweetViz and it seems to be working fine now with Jupyter Lab. As we've seen, the reports get created as HTML documents. These should go in your output folder within your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4cfd5862-5895-419d-a07c-ede209ef4403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>price_gt_1M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
       "0             3       1.00         1180      5650     1.0           0     0   \n",
       "1             3       2.25         2570      7242     2.0           0     0   \n",
       "2             2       1.00          770     10000     1.0           0     0   \n",
       "3             4       3.00         1960      5000     1.0           0     0   \n",
       "4             3       2.00         1680      8080     1.0           0     0   \n",
       "...         ...        ...          ...       ...     ...         ...   ...   \n",
       "21608         3       2.50         1530      1131     3.0           0     0   \n",
       "21609         4       2.50         2310      5813     2.0           0     0   \n",
       "21610         2       0.75         1020      1350     2.0           0     0   \n",
       "21611         3       2.50         1600      2388     2.0           0     0   \n",
       "21612         2       0.75         1020      1076     2.0           0     0   \n",
       "\n",
       "       condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "0              3      7        1180              0      1955             0   \n",
       "1              3      7        2170            400      1951          1991   \n",
       "2              3      6         770              0      1933             0   \n",
       "3              5      7        1050            910      1965             0   \n",
       "4              3      8        1680              0      1987             0   \n",
       "...          ...    ...         ...            ...       ...           ...   \n",
       "21608          3      8        1530              0      2009             0   \n",
       "21609          3      8        2310              0      2014             0   \n",
       "21610          3      7        1020              0      2009             0   \n",
       "21611          3      8        1600              0      2004             0   \n",
       "21612          3      7        1020              0      2008             0   \n",
       "\n",
       "       zipcode      lat     long  sqft_living15  sqft_lot15  price_gt_1M  \n",
       "0        98178  47.5112 -122.257           1340        5650            0  \n",
       "1        98125  47.7210 -122.319           1690        7639            0  \n",
       "2        98028  47.7379 -122.233           2720        8062            0  \n",
       "3        98136  47.5208 -122.393           1360        5000            0  \n",
       "4        98074  47.6168 -122.045           1800        7503            0  \n",
       "...        ...      ...      ...            ...         ...          ...  \n",
       "21608    98103  47.6993 -122.346           1530        1509            0  \n",
       "21609    98146  47.5107 -122.362           1830        7200            0  \n",
       "21610    98144  47.5944 -122.299           1020        2007            0  \n",
       "21611    98027  47.5345 -122.069           1410        1287            0  \n",
       "21612    98144  47.5941 -122.299           1020        1357            0  \n",
       "\n",
       "[21613 rows x 19 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.read_csv('../data/kc_house_data_classification.csv')\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f57a0813-6643-4b31-89a5-40982eba575d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   bedrooms       21613 non-null  int64  \n",
      " 1   bathrooms      21613 non-null  float64\n",
      " 2   sqft_living    21613 non-null  int64  \n",
      " 3   sqft_lot       21613 non-null  int64  \n",
      " 4   floors         21613 non-null  float64\n",
      " 5   waterfront     21613 non-null  int64  \n",
      " 6   view           21613 non-null  int64  \n",
      " 7   condition      21613 non-null  int64  \n",
      " 8   grade          21613 non-null  int64  \n",
      " 9   sqft_above     21613 non-null  int64  \n",
      " 10  sqft_basement  21613 non-null  int64  \n",
      " 11  yr_built       21613 non-null  int64  \n",
      " 12  yr_renovated   21613 non-null  int64  \n",
      " 13  zipcode        21613 non-null  int64  \n",
      " 14  lat            21613 non-null  float64\n",
      " 15  long           21613 non-null  float64\n",
      " 16  sqft_living15  21613 non-null  int64  \n",
      " 17  sqft_lot15     21613 non-null  int64  \n",
      " 18  price_gt_1M    21613 non-null  int64  \n",
      "dtypes: float64(4), int64(15)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d02260-dc4b-4a1a-8be1-8db79e037542",
   "metadata": {},
   "source": [
    "Now let's look at some automated EDA with the SweetViz package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8fbb5e91-5039-4fdd-8cb5-48254b4afca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37e14e7631d42b9a7a1e3e55c3a7784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |                                                                …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report ../output/sweetviz_report.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "report = sweetviz.analyze(housing_df)\n",
    "report.show_html(\"../output/sweetviz_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f92496e-522c-4216-a771-ed409336b67b",
   "metadata": {},
   "source": [
    "To resolve the issues with the sweetviz package, I had to install ipywidgets. It still was showing a \"Error displaying widget: model not found.\" According to this [Kaggle post](https://www.kaggle.com/product-feedback/264276), the magic solution is to just restart the jupyter lab session. That fixed my problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23762264-d717-4400-972b-935797de7fc0",
   "metadata": {},
   "source": [
    "The SweetViz output provides additional insights. There are significantly fewer houses before 1950, which makes sense due to building decay. However, there is a surprising dip in construction between 1980 and 1990. Only 5% of houses have recorded renovations. The zero insertions may make this variable problematic. \n",
    "\n",
    "The results revealed additional categorical variables. A full list is below:\n",
    "* Waterfront\n",
    "* View\n",
    "* Condition\n",
    "* Zip Code\n",
    "* Target Variables: Price over 1M\n",
    "\n",
    "According to the SweetViz output, only 7% of the houses in the data have a price greater than $1 million. The associations table shows square footage, square footage above ground, grade, bathrooms, and bedrooms have the strongest association with the target variables. Some of these features clearly have multicollinearity issues that we will need to watch for when modeling.\n",
    "\n",
    "These are just some of the interesting and important insights. The [SweetViz output file](../output/sweetviz_report.html) can provide additional detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5c8a3d-dbe2-44a1-a4f1-f0a71706d6a3",
   "metadata": {},
   "source": [
    "## Task 4 - Categorize feature types\n",
    "\n",
    "As we did in the Pump it Up class notes, we are going to need to create a list of categorical variables and a list of numeric variables so that we\n",
    "can apply the appropriate pre-processing to each. In the notes we used the data type of the columns to create lists of numeric and categorical variables. That's not necessarily going to work here as all the variables will come in as numeric. So, you'll have to come up with another way to create lists of the categorical variables and the numeric variables. \n",
    "\n",
    "Since we are using regularization, all of the numeric variables will need to rescaled using the `StandardScaler`. You'll do this later as part of the `Pipeline`. For any variables that you decide should be treated as categorical in your models, use the `OneHotEncoder` on them in the preprocessing stage.\n",
    "\n",
    "Be careful, just because a variable has a numeric datatype in the pandas dataframe, it does **not** mean that it's necessarily a numeric variable in the context of the classification models. Think about each column and look at your EDA reports and decide whether or not it's truly numeric or needs to be treated as categorical data in the models.  \n",
    "\n",
    "Even though our target variable, `price_gt_1M`, is categorical, you do **NOT** need to do any preprocessing on it. As I mentioned in our class notes, scikit-learn will automatically detect that and will do any encoding needed on its own.\n",
    "\n",
    "Finally, you'll partition the dataset into training and test datasets for modeling: \n",
    "\n",
    "* I broke up the `housing_df` into two separate dataframes that I called `X` and `y`, to use in the models. Here's my code for that:\n",
    "\n",
    "```\n",
    "X = housing_df.iloc[:, 0:18]\n",
    "y = housing_df.iloc[:, 18]\n",
    "```\n",
    "\n",
    "* Please use the following code for your data partitioning so that we all end up with the same training and test split:\n",
    "\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=73)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abf766d7-65ad-48a5-9f33-b4e94580edcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_lot',\n",
       " 'floors',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'condition',\n",
       " 'grade',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'zipcode',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'sqft_living15',\n",
       " 'sqft_lot15',\n",
       " 'price_gt_1M']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_names = housing_df.columns.tolist()\n",
    "all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "454963bd-0dcb-4590-b285-f7db76ef371c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   bedrooms       21613 non-null  int64   \n",
      " 1   bathrooms      21613 non-null  float64 \n",
      " 2   sqft_living    21613 non-null  int64   \n",
      " 3   sqft_lot       21613 non-null  int64   \n",
      " 4   floors         21613 non-null  float64 \n",
      " 5   waterfront     21613 non-null  category\n",
      " 6   view           21613 non-null  category\n",
      " 7   condition      21613 non-null  category\n",
      " 8   grade          21613 non-null  int64   \n",
      " 9   sqft_above     21613 non-null  int64   \n",
      " 10  sqft_basement  21613 non-null  int64   \n",
      " 11  yr_built       21613 non-null  int64   \n",
      " 12  yr_renovated   21613 non-null  int64   \n",
      " 13  zipcode        21613 non-null  category\n",
      " 14  lat            21613 non-null  float64 \n",
      " 15  long           21613 non-null  float64 \n",
      " 16  sqft_living15  21613 non-null  int64   \n",
      " 17  sqft_lot15     21613 non-null  int64   \n",
      " 18  price_gt_1M    21613 non-null  int64   \n",
      "dtypes: category(4), float64(4), int64(11)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "#Change varaibles to categorical\n",
    "cat_vars_names = ['waterfront', 'view', 'condition', 'zipcode']\n",
    "for x in cat_vars_names:\n",
    "    housing_df[x] = housing_df[x].astype(\"category\")\n",
    "    \n",
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d269a-b9d0-4722-9f7f-76f5b4958e5b",
   "metadata": {},
   "source": [
    "I also considered changing bedrooms, bathrooms, floors, year built and year renovated to categorical variables because fractional values make less sense for these values. However, I ultimately decided against it. This could be an area for further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ee425ad-237e-495d-ac72-b2540b72f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating testing and training vectors\n",
    "X = housing_df.iloc[:, 0:18]\n",
    "y = housing_df.iloc[:, 18]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=73)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7dd923-a0c3-4e29-bcbb-615074e0f2d6",
   "metadata": {},
   "source": [
    "### Create lists of categorical and numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e931a7b-0523-434a-9194-49b70cccb415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of numeric and categorical variable names\n",
    "cat_vars = X_train.select_dtypes(include = ['category']).columns.tolist()\n",
    "num_vars = X_train.select_dtypes(include = ['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb80091e-256a-41d1-883f-884b854127f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['waterfront', 'view', 'condition', 'zipcode']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50d6c4a4-1e54-4c98-8695-c0e33774117b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_lot',\n",
       " 'floors',\n",
       " 'grade',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'sqft_living15',\n",
       " 'sqft_lot15']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "72642e4c-e657-4e43-9053-2cfed901a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars_idx = [X_train.columns.get_loc(c) for c in cat_vars]\n",
    "num_vars_idx = [X_train.columns.get_loc(c) for c in num_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a5369e-9a7d-4aca-99db-2c5b474ba401",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Normalize and recode the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b7f648d-fef3-4d2d-8812-5125a405fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the transformers\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine transformers into a preprocessor step\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_vars),\n",
    "        ('cat', cat_transformer, cat_vars)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe10bc-e39d-42b5-b764-e1acca69f521",
   "metadata": {},
   "source": [
    "## Task 5 - Logistic regression models\n",
    "\n",
    "You are going to build a few different logistic regression models using all of the variables in our housing dataset. For each of these models you will:\n",
    "\n",
    "- Create a pipeline to do the preprocessing (the scaling and encoding) and the modeling (we did this in the Pump it Up project)\n",
    "- I'll be giving you different specifications and hyperparameter parameter settings to try\n",
    "- You'll be scoring the models on overall accuracy for both the training and test data. Discuss any evidence of overfitting or underfitting as well as how the model does in comparison to the null model.\n",
    "- There will be some additional tasks/questions for each model - details below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d4b5b4-94cf-44ba-9c02-a645ccf9d7f3",
   "metadata": {},
   "source": [
    "#### Null Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd06bb-5dff-4738-8f86-5130887ef60e",
   "metadata": {},
   "source": [
    "Since we are just looking at a binary varaible, I can use the 'most frequent' strategy for the `DummyClassifier()` method. However, multiple target levels would require a different selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1fdee697-94eb-4343-8500-31f3d7c9a7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: 0.933\n",
      "Test model: 0.924\n"
     ]
    }
   ],
   "source": [
    "# Create the Model\n",
    "null_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# Fit the Model\n",
    "null_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Model\n",
    "null_clf.predict(X_test)\n",
    "\n",
    "#Score the model\n",
    "print(f'Training model: {null_clf.score(X_train, y_train):.3f}')\n",
    "print(f'Test model: {null_clf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0621266-3ca5-4f70-960c-6ea36a7c6161",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "\n",
    "Build a ridge regression model to predict `price_gt_1M` and use the default value of `C=1.0`. I used the following additional options with the `LogisticRegression` model - `solver='saga', max_iter=2000`. Feel free to change these if you want. AFter fitting the model, compute its accuracy score for training and test and write out a little summary (f-strings are useful). Here's an example:\n",
    "\n",
    "    Training score: 0.974\n",
    "    Test score: 0.971\n",
    "\n",
    "Create confusion matrices for both training and test.\n",
    "\n",
    "Also, create a plot of the coefficients (as we did in the notes). If you want to use that `coef_plot` function we used in the notes, you'll have\n",
    "to make a few modifications because we only have one set of coefficients (since we have a binary classification problem as opposed to a 3-class problem in Pump it Up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc92dd-f1c5-4ecc-b3cc-4e3839cbf137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Model\n",
    "clf2 = LogisticRegression(penalty='l2', C=1.0, solver='saga', max_iter=2000)\n",
    "\n",
    "#Normalization\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', model1_clf)])\n",
    "\n",
    "# Fit the Model\n",
    "model1_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Model\n",
    "model1_clf.predict(X_test)\n",
    "\n",
    "#Score the model\n",
    "print(f'Training model: {model1_clf.score(X_train, y_train):.3f}')\n",
    "print(f'Test model: {model1_clf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2470c8d-42d1-4b63-b7cb-9b1d1ff7d448",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    ">>> dummy_clf.fit(X, y)\n",
    "DummyClassifier(strategy='most_frequent')\n",
    ">>> dummy_clf.predict(X)\n",
    "array([1, 1, 1, 1])\n",
    ">>> dummy_clf.score(X, y)\n",
    "\n",
    "\n",
    "# Classifier model\n",
    "null_clf_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "null\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', null_clf_model)])\n",
    "\n",
    "LogisticRegression(penalty='l2', C=1, solver='saga', max_iter=500)\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', null_clf_model)])\n",
    "\n",
    "#Create confusion matrix\n",
    "titles_options = [(\"Confusion matrix for null model\", None),\n",
    "                  (\"Normalized confusion matrix for train\", 'true')]\n",
    "\n",
    "class_names = null_clf['classifier'].classes_\n",
    "\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(null_clf, X_train, y_train,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1477166-1cfe-41ca-b39d-aaaa775899ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aap]",
   "language": "python",
   "name": "conda-env-aap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
